{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd6dfa9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe will change the learning rates in the midst of the code:\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "We will change the learning rates in the midst of the code. We can by:\n",
    "1) Time (training epoch)\n",
    "2) Derivative\n",
    "3) Loss\n",
    "4) Current local minimum value\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a77b5e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qm/y3ntm4w54lv2x8p86n_p1ml80000gn/T/ipykernel_39305/2884596146.py:5: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  display.set_matplotlib_formats('svg')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4a7d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function and its derivative\n",
    "x = np.linspace(-2,2,2001)\n",
    "\n",
    "def fx(x):\n",
    "    return 3*x** - 3*x + 4\n",
    "\n",
    "def deriv(x):\n",
    "    return 6*x - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23459d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient descent using a fixed learning rate\n",
    "\n",
    "#random starting point\n",
    "localmin=np.random.choice(x,1)\n",
    "initial=localmin[:]\n",
    "\n",
    "#learning parameterers\n",
    "learning_rate=.01\n",
    "training_epochs=50\n",
    "\n",
    "#run through training and store all the results\n",
    "modelparamsFixed = np.zeros((training_epochs,3))\n",
    "for i in range(training_epochs):\n",
    "    \n",
    "    #compute gradient\n",
    "    grad=deriv(localmin)\n",
    "    \n",
    "    #non-adaptive learning rate\n",
    "    lr = learning_rate\n",
    "    \n",
    "    #update parameter according to g.d.\n",
    "    localmin = localmin - lr * grad\n",
    "    \n",
    "    #store the parameters\n",
    "    modelparamsFixed[i, 0] = localmin\n",
    "    modelparamsFixed[i, 1] = grad\n",
    "    modelparamsFixed[i, 2] = lr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c691aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GD using a gradient-based learning rate\n",
    "\n",
    "#random starting point\n",
    "localmin = np.random.choice(x,1)\n",
    "initial = localmin[:]\n",
    "\n",
    "#learning parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 50\n",
    "\n",
    "#run through training and store all the results\n",
    "modelparamsGrad = np.zeros((training_epochs,3))\n",
    "\n",
    "for i in range(training_epochs):\n",
    "    \n",
    "    #compute gradient\n",
    "    grad = deriv(localmin)\n",
    "    \n",
    "    #adapt the learning rate according to the gradient\n",
    "    lr = learning_rate * np.abs(grad)\n",
    "    \n",
    "    #update parameter according to g.d.\n",
    "    localin = localmin - lr * grad\n",
    "    \n",
    "    #store parameters\n",
    "    modelparamsGrad[i,0]=localmin\n",
    "    modelparamsGrad[i,1]=grad\n",
    "    modelparamsGrad[i,2]=lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ad68193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe main idea here is when we are very far away from the dunction minimum,\\nthe gradient is relatively large. That means the learning rate is relatively\\nlarger. Conversely, the closer we get to the actual function minimum, the \\ngradient gets closer and closer to 0. That means the effective learning\\nrate decreases. The learning rate is going to go towards 0 as the gradient \\ngets smaller.\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The main idea here is when we are very far away from the dunction minimum,\n",
    "the gradient is relatively large. That means the learning rate is relatively\n",
    "larger. Conversely, the closer we get to the actual function minimum, the \n",
    "gradient gets closer and closer to 0. That means the effective learning\n",
    "rate decreases. The learning rate is going to go towards 0 as the gradient \n",
    "gets smaller.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3025bb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dynamic gradient descent using a time-based learing rate\n",
    "\n",
    "#redefine parameters\n",
    "learning_rate = .1\n",
    "localmin = initial\n",
    "\n",
    "#run through training and store all the results\n",
    "modelparamsTime = np.zeros((training_epochs,3))\n",
    "for i in range(training_epochs):\n",
    "    grad = deriv(localmin)\n",
    "    lr = learning_rate * (1- ((i+1)/training_epochs))\n",
    "    localmin = localmin - lr * grad\n",
    "    modelparamsGrad[i,0]=localmin\n",
    "    modelparamsGrad[i,1]=grad\n",
    "    modelparamsGrad[i,2]=lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d1b6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here, the value of (i+1)/training_epochs) is very low. So 1 gets reduced\n",
    "by a very small account. But as  i increases and gets closer to 50, \n",
    "(i+1)/training_epochs) becomes closer to 1 and the value subsequently \n",
    "becomes closer to 0 which means the effective learning rate is decreasing\n",
    "as the learning increases.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf925e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
